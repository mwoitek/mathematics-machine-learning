{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram-Schmidt process\n",
    "\n",
    "## Instructions\n",
    "In this assignment you will write a function to perform the Gram-Schmidt procedure, which takes a list of vectors and forms an orthonormal basis from this set.\n",
    "As a corollary, the procedure allows us to determine the dimension of the space spanned by the basis vectors, which is equal to or less than the space which the vectors sit.\n",
    "\n",
    "You'll start by completing a function for 4 basis vectors, before generalising to when an arbitrary number of vectors are given.\n",
    "\n",
    "Again, a framework for the function has already been written.\n",
    "Look through the code, and you'll be instructed where to make changes.\n",
    "We'll do the first two rows, and you can use this as a guide to do the last two.\n",
    "\n",
    "### Matrices in Python\n",
    "Remember the structure for matrices in *numpy* is,\n",
    "```python\n",
    "A[0, 0]  A[0, 1]  A[0, 2]  A[0, 3]\n",
    "A[1, 0]  A[1, 1]  A[1, 2]  A[1, 3]\n",
    "A[2, 0]  A[2, 1]  A[2, 2]  A[2, 3]\n",
    "A[3, 0]  A[3, 1]  A[3, 2]  A[3, 3]\n",
    "```\n",
    "You can access the value of each element individually using,\n",
    "```python\n",
    "A[n, m]\n",
    "```\n",
    "You can also access a whole row at a time using,\n",
    "```python\n",
    "A[n]\n",
    "```\n",
    "\n",
    "Building on last assignment, in this exercise you will need to select whole columns at a time.\n",
    "This can be done with,\n",
    "```python\n",
    "A[:, m]\n",
    "```\n",
    "which will select the m'th column (starting at zero).\n",
    "\n",
    "In this exercise, you will need to take the dot product between vectors. This can be done using the @ operator.\n",
    "To dot product vectors u and v, use the code,\n",
    "```python\n",
    "u @ v\n",
    "```\n",
    "\n",
    "All the code you should complete will be at the same level of indentation as the instruction comment.\n",
    "\n",
    "### How to submit\n",
    "Edit the code in the cell below to complete the assignment.\n",
    "Once you are finished and happy with it, press the *Submit Assignment* button at the top of this notebook.\n",
    "\n",
    "Please don't change any of the function names, as these will be checked by the grading script.\n",
    "\n",
    "If you have further questions about submissions or programming assignments, here is a [list](https://www.coursera.org/learn/linear-algebra-machine-learning/discussions/weeks/1/threads/jB4klkn5EeibtBIQyzFmQg) of Q&A. You can also raise an issue on the discussion forum. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "\n",
    "verySmallNumber = 1e-14\n",
    "\n",
    "# Our first function will perform the Gram-Schmidt procedure for 4 basis\n",
    "# vectors. We'll take this list of vectors as the columns of a matrix, A.\n",
    "# We'll then go through the vectors one at a time and set them to be orthogonal\n",
    "# to all the vectors that came before it.\n",
    "def gsBasis4(A):\n",
    "\n",
    "    # Make B as a copy of A, since we're going to alter its values:\n",
    "    B = np.array(A, dtype=np.float_)\n",
    "\n",
    "    # The zeroth column is easy, since it has no other vectors to make it\n",
    "    # normal to. All that needs to be done is to normalize it.\n",
    "    B[:, 0] /= la.norm(B[:, 0])\n",
    "\n",
    "    # For the first column, we need to subtract any overlap with our new zeroth\n",
    "    # vector:\n",
    "    B[:, 1] -= B[:, 1] @ B[:, 0] * B[:, 0]\n",
    "\n",
    "    # If there's anything left after that subtraction, then B[:, 1] is linearly\n",
    "    # independent of B[:, 0]. If this is the case, we can normalize it.\n",
    "    # Otherwise we'll set that vector to zero.\n",
    "    tmp = la.norm(B[:, 1])\n",
    "    if tmp > verySmallNumber:\n",
    "        B[:, 1] /= tmp\n",
    "    else:\n",
    "        B[:, 1] = np.zeros_like(B[:, 1])\n",
    "\n",
    "    # Now we need to repeat the process for column 2.\n",
    "    # Subtract the overlap with the zeroth vector:\n",
    "    B[:, 2] -= B[:, 2] @ B[:, 0] * B[:, 0]\n",
    "    # Subtract the overlap with the first vector:\n",
    "    B[:, 2] -= B[:, 2] @ B[:, 1] * B[:, 1]\n",
    "\n",
    "    # Again we'll need to normalize our new vector:\n",
    "    tmp = la.norm(B[:, 2])\n",
    "    if tmp > verySmallNumber:\n",
    "        B[:, 2] /= tmp\n",
    "    else:\n",
    "        B[:, 2] = np.zeros_like(B[:, 2])\n",
    "\n",
    "    # Now we need to repeat the process for column 3.\n",
    "    # Subtract the overlap with the zeroth vector:\n",
    "    B[:, 3] -= B[:, 3] @ B[:, 0] * B[:, 0]\n",
    "    # Subtract the overlap with the first vector:\n",
    "    B[:, 3] -= B[:, 3] @ B[:, 1] * B[:, 1]\n",
    "    # Subtract the overlap with the second vector:\n",
    "    B[:, 3] -= B[:, 3] @ B[:, 2] * B[:, 2]\n",
    "\n",
    "    # Again we'll need to normalize our new vector:\n",
    "    tmp = la.norm(B[:, 3])\n",
    "    if tmp > verySmallNumber:\n",
    "        B[:, 3] /= tmp\n",
    "    else:\n",
    "        B[:, 3] = np.zeros_like(B[:, 3])\n",
    "\n",
    "    return B\n",
    "\n",
    "\n",
    "# The second part of this exercise will generalize the procedure. Previously,\n",
    "# we could only have four vectors, and there was a lot of repeating in the\n",
    "# code. We'll use a for-loop here to iterate the process for each vector.\n",
    "def gsBasis(A):\n",
    "\n",
    "    # Make B as a copy of A, since we're going to alter its values:\n",
    "    B = np.array(A, dtype=np.float_)\n",
    "\n",
    "    # Loop over all vectors:\n",
    "    for i in range(B.shape[1]):\n",
    "        # Loop over all previous vectors:\n",
    "        for j in range(i):\n",
    "            # Subtract the overlap with previous vectors:\n",
    "            B[:, i] -= B[:, i] @ B[:, j] * B[:, j]\n",
    "        # Normalization test for B[:, i]:\n",
    "        tmp = la.norm(B[:, i])\n",
    "        if tmp > verySmallNumber:\n",
    "            B[:, i] /= tmp\n",
    "        else:\n",
    "            B[:, i] = np.zeros_like(B[:, i])\n",
    "\n",
    "    return B\n",
    "\n",
    "\n",
    "# This function uses the Gram-Schmidt process to calculate the dimension of the\n",
    "# space spanned by a list of vectors. Since each vector is normalized to one,\n",
    "# or is zero, the sum of all the norms will be the dimension.\n",
    "def dimensions(A):\n",
    "    return np.sum(la.norm(gsBasis(A), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your code before submission\n",
    "To test the code you've written above, run the cell (select the cell above, then press the play button [ â–¶| ] or press shift-enter).\n",
    "You can then use the code below to test out your function.\n",
    "You don't need to submit this cell; you can edit and run it as much as you like.\n",
    "\n",
    "Try out your code on tricky test cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.1814885 ,  0.04982278,  0.89325973],\n",
       "       [ 0.        ,  0.1088931 ,  0.99349591, -0.03328918],\n",
       "       [ 0.81649658,  0.50816781, -0.06462163, -0.26631346],\n",
       "       [ 0.40824829, -0.83484711,  0.07942048, -0.36063281]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([[1,  0, 2, 6],\n",
    "              [0,  1, 8, 2],\n",
    "              [2,  8, 3, 1],\n",
    "              [1, -6, 2, 3]], dtype=np.float_)\n",
    "gsBasis4(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.1814885 ,  0.04982278,  0.89325973],\n",
       "       [ 0.        ,  0.1088931 ,  0.99349591, -0.03328918],\n",
       "       [ 0.81649658,  0.50816781, -0.06462163, -0.26631346],\n",
       "       [ 0.40824829, -0.83484711,  0.07942048, -0.36063281]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once you've done Gram-Schmidt, doing it again should give you the same result.\n",
    "U = gsBasis4(V)\n",
    "gsBasis4(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.1814885 ,  0.04982278,  0.89325973],\n",
       "       [ 0.        ,  0.1088931 ,  0.99349591, -0.03328918],\n",
       "       [ 0.81649658,  0.50816781, -0.06462163, -0.26631346],\n",
       "       [ 0.40824829, -0.83484711,  0.07942048, -0.36063281]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the general function too:\n",
    "gsBasis(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23643312,  0.18771349,  0.22132104],\n",
       "       [ 0.15762208,  0.74769023, -0.64395812],\n",
       "       [ 0.15762208,  0.57790444,  0.72904263],\n",
       "       [ 0.94573249, -0.26786082, -0.06951101]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what happens for non-square matrices:\n",
    "A = np.array([[ 3, 2,  3],\n",
    "              [ 2, 5, -1],\n",
    "              [ 2, 4,  8],\n",
    "              [12, 2,  1]], dtype=np.float_)\n",
    "gsBasis(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93704257, -0.12700832, -0.32530002,  0.        ,  0.        ],\n",
       "       [ 0.31234752,  0.72140727,  0.61807005,  0.        ,  0.        ],\n",
       "       [ 0.15617376, -0.6807646 ,  0.71566005,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[6,  2, 1,  7, 5],\n",
    "              [2,  8, 5, -4, 1],\n",
    "              [1, -6, 3,  2, 8]], dtype=np.float_)\n",
    "gsBasis(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.70710678,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what happens when we have one vector that is a linear combination of the others:\n",
    "C = np.array([[1, 0,  2],\n",
    "              [0, 1, -3],\n",
    "              [1, 0,  2]], dtype=np.float_)\n",
    "gsBasis(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(C)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "linear-algebra-machine-learning",
   "graded_item_id": "FNk8v",
   "launcher_item_id": "DdvVk"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
